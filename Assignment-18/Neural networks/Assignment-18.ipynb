{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b64ec5",
   "metadata": {},
   "source": [
    "## ARTIFICIAL NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d1817",
   "metadata": {},
   "source": [
    "## 1. Data Exploration and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f119afc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kavana\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\kavana\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_api' from partially initialized module 'matplotlib' (most likely due to a circular import) (C:\\Users\\kavana\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\__init__.py:107\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cbook, rcsetup\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning, sanitize_sequence\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mplDeprecation  \u001b[38;5;66;03m# deprecated\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\rcsetup.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m animation, cbook\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\animation.py:41\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_animation_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     DISPLAY_TEMPLATE, INCLUDED_FRAMES, JS_INCLUDE, STYLE_INCLUDE)\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmcolors\u001b[39;00m\n\u001b[0;32m     44\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_api' from partially initialized module 'matplotlib' (most likely due to a circular import) (C:\\Users\\kavana\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65867b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"Alphabets_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aef7272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c7b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b50bcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.023550</td>\n",
       "      <td>7.035500</td>\n",
       "      <td>5.121850</td>\n",
       "      <td>5.37245</td>\n",
       "      <td>3.505850</td>\n",
       "      <td>6.897600</td>\n",
       "      <td>7.500450</td>\n",
       "      <td>4.628600</td>\n",
       "      <td>5.178650</td>\n",
       "      <td>8.282050</td>\n",
       "      <td>6.45400</td>\n",
       "      <td>7.929000</td>\n",
       "      <td>3.046100</td>\n",
       "      <td>8.338850</td>\n",
       "      <td>3.691750</td>\n",
       "      <td>7.80120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.913212</td>\n",
       "      <td>3.304555</td>\n",
       "      <td>2.014573</td>\n",
       "      <td>2.26139</td>\n",
       "      <td>2.190458</td>\n",
       "      <td>2.026035</td>\n",
       "      <td>2.325354</td>\n",
       "      <td>2.699968</td>\n",
       "      <td>2.380823</td>\n",
       "      <td>2.488475</td>\n",
       "      <td>2.63107</td>\n",
       "      <td>2.080619</td>\n",
       "      <td>2.332541</td>\n",
       "      <td>1.546722</td>\n",
       "      <td>2.567073</td>\n",
       "      <td>1.61747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               xbox          ybox         width       height         onpix  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
       "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
       "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
       "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
       "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
       "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
       "\n",
       "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
       "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
       "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
       "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
       "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
       "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
       "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
       "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
       "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
       "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            yedgex  \n",
       "count  20000.00000  \n",
       "mean       7.80120  \n",
       "std        1.61747  \n",
       "min        0.00000  \n",
       "25%        7.00000  \n",
       "50%        8.00000  \n",
       "75%        9.00000  \n",
       "max       15.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0f7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing value\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c0110d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1332"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c4c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate data\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a67024cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ff46b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['T', 'I', 'D', 'N', 'G', 'S', 'B', 'A', 'J', 'M', 'X', 'O', 'R',\n",
       "       'F', 'C', 'H', 'W', 'L', 'P', 'E', 'V', 'Y', 'Q', 'U', 'K', 'Z'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['letter'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018b3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x = df.drop(columns=['letter'])\n",
    "y = df['letter']\n",
    "\n",
    "#mimax scaler\n",
    "scaler = MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f15acbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encode the target variable\n",
    "encoder = OneHotEncoder()\n",
    "y_en = encoder.fit_transform(y.values.reshape(-1, 1))\n",
    "y_encoded = pd.DataFrame(y_en.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f41eb7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18663</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18664</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18665</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18666</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18667</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18668 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9   ...   16   17   18  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "18663  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18664  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18665  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18666  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18667  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "        19   20   21   22   23   24   25  \n",
       "0      1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "18663  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18664  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18665  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18666  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18667  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[18668 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd577a",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9eab74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f35cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8204a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential([\n",
    "    Dense(12, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(26, activation='softmax') \n",
    "]) \n",
    "\n",
    "# since its a multiclass classification problem so im using relu for hidden layer and softmax for output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "947adb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#I'm using adam optimizer bcz it uses both adagrad and rmsprop properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f9b2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "598/598 [==============================] - 2s 3ms/step - loss: 3.1339 - accuracy: 0.1318 - val_loss: 2.9413 - val_accuracy: 0.2126\n",
      "Epoch 2/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 2.7150 - accuracy: 0.3022 - val_loss: 2.4918 - val_accuracy: 0.3622\n",
      "Epoch 3/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 2.3005 - accuracy: 0.4287 - val_loss: 2.1553 - val_accuracy: 0.4707\n",
      "Epoch 4/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 2.0333 - accuracy: 0.4846 - val_loss: 1.9541 - val_accuracy: 0.4821\n",
      "Epoch 5/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.8618 - accuracy: 0.5152 - val_loss: 1.8211 - val_accuracy: 0.5149\n",
      "Epoch 6/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.7421 - accuracy: 0.5405 - val_loss: 1.7271 - val_accuracy: 0.5330\n",
      "Epoch 7/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.6528 - accuracy: 0.5596 - val_loss: 1.6468 - val_accuracy: 0.5591\n",
      "Epoch 8/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.5830 - accuracy: 0.5750 - val_loss: 1.5900 - val_accuracy: 0.5571\n",
      "Epoch 9/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.5243 - accuracy: 0.5939 - val_loss: 1.5382 - val_accuracy: 0.5765\n",
      "Epoch 10/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.4759 - accuracy: 0.6006 - val_loss: 1.4962 - val_accuracy: 0.5859\n",
      "Epoch 11/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.4333 - accuracy: 0.6123 - val_loss: 1.4630 - val_accuracy: 0.5956\n",
      "Epoch 12/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.3971 - accuracy: 0.6217 - val_loss: 1.4285 - val_accuracy: 0.6063\n",
      "Epoch 13/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.3657 - accuracy: 0.6318 - val_loss: 1.3970 - val_accuracy: 0.6076\n",
      "Epoch 14/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.3373 - accuracy: 0.6338 - val_loss: 1.3758 - val_accuracy: 0.6227\n",
      "Epoch 15/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.3121 - accuracy: 0.6407 - val_loss: 1.3553 - val_accuracy: 0.6150\n",
      "Epoch 16/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.2904 - accuracy: 0.6479 - val_loss: 1.3339 - val_accuracy: 0.6284\n",
      "Epoch 17/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.2692 - accuracy: 0.6501 - val_loss: 1.3118 - val_accuracy: 0.6344\n",
      "Epoch 18/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.2509 - accuracy: 0.6549 - val_loss: 1.2973 - val_accuracy: 0.6445\n",
      "Epoch 19/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.2344 - accuracy: 0.6601 - val_loss: 1.2869 - val_accuracy: 0.6425\n",
      "Epoch 20/20\n",
      "598/598 [==============================] - 1s 2ms/step - loss: 1.2190 - accuracy: 0.6634 - val_loss: 1.2715 - val_accuracy: 0.6455\n"
     ]
    }
   ],
   "source": [
    "training = model1.fit(x_train, y_train_encoded, epochs=20, batch_size=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4654e0",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4816934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "285/285 [==============================] - 2s 3ms/step - loss: 3.1268 - accuracy: 0.1477 - val_loss: 2.9642 - val_accuracy: 0.2695\n",
      "Epoch 2/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 2.7496 - accuracy: 0.3679 - val_loss: 2.5430 - val_accuracy: 0.4443\n",
      "Epoch 3/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 2.3480 - accuracy: 0.4640 - val_loss: 2.1910 - val_accuracy: 0.4633\n",
      "Epoch 4/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 2.0430 - accuracy: 0.5132 - val_loss: 1.9509 - val_accuracy: 0.5303\n",
      "Epoch 5/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.8325 - accuracy: 0.5524 - val_loss: 1.7792 - val_accuracy: 0.5608\n",
      "Epoch 6/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.6865 - accuracy: 0.5844 - val_loss: 1.6557 - val_accuracy: 0.5815\n",
      "Epoch 7/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.5769 - accuracy: 0.6058 - val_loss: 1.5706 - val_accuracy: 0.5976\n",
      "Epoch 8/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.4937 - accuracy: 0.6245 - val_loss: 1.5049 - val_accuracy: 0.6006\n",
      "Epoch 9/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.4267 - accuracy: 0.6367 - val_loss: 1.4465 - val_accuracy: 0.6160\n",
      "Epoch 10/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.3715 - accuracy: 0.6517 - val_loss: 1.3952 - val_accuracy: 0.6321\n",
      "Epoch 11/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.3255 - accuracy: 0.6628 - val_loss: 1.3529 - val_accuracy: 0.6485\n",
      "Epoch 12/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.2856 - accuracy: 0.6745 - val_loss: 1.3225 - val_accuracy: 0.6558\n",
      "Epoch 13/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.2503 - accuracy: 0.6836 - val_loss: 1.2942 - val_accuracy: 0.6642\n",
      "Epoch 14/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.2202 - accuracy: 0.6890 - val_loss: 1.2716 - val_accuracy: 0.6649\n",
      "Epoch 15/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1930 - accuracy: 0.6971 - val_loss: 1.2322 - val_accuracy: 0.6722\n",
      "Epoch 16/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1682 - accuracy: 0.7008 - val_loss: 1.2159 - val_accuracy: 0.6813\n",
      "Epoch 17/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1458 - accuracy: 0.7079 - val_loss: 1.1927 - val_accuracy: 0.6820\n",
      "Epoch 18/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1256 - accuracy: 0.7105 - val_loss: 1.1804 - val_accuracy: 0.6836\n",
      "Epoch 19/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1073 - accuracy: 0.7164 - val_loss: 1.1658 - val_accuracy: 0.6866\n",
      "Epoch 20/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.0907 - accuracy: 0.7162 - val_loss: 1.1464 - val_accuracy: 0.6920\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(56, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(26, activation='sigmoid') \n",
    "]) \n",
    "model2.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "training = model2.fit(x_train, y_train_encoded, epochs=20, batch_size=42, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a9e6b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "285/285 [==============================] - 2s 4ms/step - loss: 3.0438 - accuracy: 0.2134 - val_loss: 2.7835 - val_accuracy: 0.3545\n",
      "Epoch 2/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 2.4970 - accuracy: 0.4337 - val_loss: 2.2328 - val_accuracy: 0.5018\n",
      "Epoch 3/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 2.0276 - accuracy: 0.5439 - val_loss: 1.8726 - val_accuracy: 0.5631\n",
      "Epoch 4/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.7367 - accuracy: 0.5960 - val_loss: 1.6574 - val_accuracy: 0.5926\n",
      "Epoch 5/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.5547 - accuracy: 0.6234 - val_loss: 1.5167 - val_accuracy: 0.6127\n",
      "Epoch 6/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.4347 - accuracy: 0.6438 - val_loss: 1.4270 - val_accuracy: 0.6364\n",
      "Epoch 7/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.3485 - accuracy: 0.6604 - val_loss: 1.3564 - val_accuracy: 0.6435\n",
      "Epoch 8/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.2840 - accuracy: 0.6716 - val_loss: 1.3027 - val_accuracy: 0.6625\n",
      "Epoch 9/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.2348 - accuracy: 0.6842 - val_loss: 1.2586 - val_accuracy: 0.6763\n",
      "Epoch 10/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1954 - accuracy: 0.6912 - val_loss: 1.2287 - val_accuracy: 0.6880\n",
      "Epoch 11/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1626 - accuracy: 0.7027 - val_loss: 1.2113 - val_accuracy: 0.6826\n",
      "Epoch 12/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1346 - accuracy: 0.7030 - val_loss: 1.1879 - val_accuracy: 0.6970\n",
      "Epoch 13/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.1142 - accuracy: 0.7100 - val_loss: 1.1569 - val_accuracy: 0.7027\n",
      "Epoch 14/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.0934 - accuracy: 0.7113 - val_loss: 1.1555 - val_accuracy: 0.6937\n",
      "Epoch 15/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.0757 - accuracy: 0.7183 - val_loss: 1.1273 - val_accuracy: 0.7037\n",
      "Epoch 16/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.0608 - accuracy: 0.7185 - val_loss: 1.1135 - val_accuracy: 0.7118\n",
      "Epoch 17/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.0460 - accuracy: 0.7248 - val_loss: 1.1018 - val_accuracy: 0.7148\n",
      "Epoch 18/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.0356 - accuracy: 0.7276 - val_loss: 1.0888 - val_accuracy: 0.7171\n",
      "Epoch 19/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.0247 - accuracy: 0.7304 - val_loss: 1.0817 - val_accuracy: 0.7164\n",
      "Epoch 20/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 1.0144 - accuracy: 0.7300 - val_loss: 1.0695 - val_accuracy: 0.7174\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential([\n",
    "    Dense(56, activation='elu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(26, activation='sigmoid') \n",
    "]) \n",
    "model3.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "training = model3.fit(x_train, y_train_encoded, epochs=20, batch_size=42, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b715d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "285/285 [==============================] - 2s 3ms/step - loss: 3.2987 - accuracy: 0.0393 - val_loss: 3.2784 - val_accuracy: 0.0485\n",
      "Epoch 2/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.2707 - accuracy: 0.0468 - val_loss: 3.2584 - val_accuracy: 0.0529\n",
      "Epoch 3/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.2538 - accuracy: 0.0537 - val_loss: 3.2447 - val_accuracy: 0.0619\n",
      "Epoch 4/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.2414 - accuracy: 0.0633 - val_loss: 3.2338 - val_accuracy: 0.0743\n",
      "Epoch 5/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.2313 - accuracy: 0.0696 - val_loss: 3.2246 - val_accuracy: 0.0763\n",
      "Epoch 6/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.2224 - accuracy: 0.0703 - val_loss: 3.2164 - val_accuracy: 0.0780\n",
      "Epoch 7/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.2145 - accuracy: 0.0709 - val_loss: 3.2089 - val_accuracy: 0.0753\n",
      "Epoch 8/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.2072 - accuracy: 0.0765 - val_loss: 3.2020 - val_accuracy: 0.0787\n",
      "Epoch 9/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.2003 - accuracy: 0.0826 - val_loss: 3.1954 - val_accuracy: 0.0860\n",
      "Epoch 10/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1938 - accuracy: 0.0891 - val_loss: 3.1891 - val_accuracy: 0.0937\n",
      "Epoch 11/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1876 - accuracy: 0.0973 - val_loss: 3.1830 - val_accuracy: 0.1028\n",
      "Epoch 12/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1815 - accuracy: 0.1043 - val_loss: 3.1772 - val_accuracy: 0.1118\n",
      "Epoch 13/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1757 - accuracy: 0.1138 - val_loss: 3.1715 - val_accuracy: 0.1175\n",
      "Epoch 14/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1700 - accuracy: 0.1213 - val_loss: 3.1660 - val_accuracy: 0.1242\n",
      "Epoch 15/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1645 - accuracy: 0.1290 - val_loss: 3.1605 - val_accuracy: 0.1309\n",
      "Epoch 16/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1591 - accuracy: 0.1379 - val_loss: 3.1552 - val_accuracy: 0.1376\n",
      "Epoch 17/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1537 - accuracy: 0.1446 - val_loss: 3.1500 - val_accuracy: 0.1419\n",
      "Epoch 18/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1485 - accuracy: 0.1526 - val_loss: 3.1449 - val_accuracy: 0.1480\n",
      "Epoch 19/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1434 - accuracy: 0.1589 - val_loss: 3.1399 - val_accuracy: 0.1557\n",
      "Epoch 20/20\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 3.1383 - accuracy: 0.1648 - val_loss: 3.1349 - val_accuracy: 0.1600\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential([\n",
    "    Dense(56, activation='tanh', input_shape=(x_train.shape[1],)),\n",
    "    Dense(26, activation='sigmoid') \n",
    "]) \n",
    "model4.compile(optimizer='ADAgrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "training = model4.fit(x_train, y_train_encoded, epochs=20, batch_size=42, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e345f33",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec689996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with relu , softmax and adam optimizer \n",
      "Accuracy: 0.6580074986609534\n",
      "Precision: 0.6669922510520271\n",
      "Recall: 0.6580074986609534\n",
      "F1-score: 0.6536043011238042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "# Get the true labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Get the predicted labels\n",
    "y_pred = np.argmax(model1.predict(x_test), axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Model with relu , softmax and adam optimizer \")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93a9f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with relu , sigmoid and RMSprop\n",
      "Accuracy: 0.7038028923406534\n",
      "Precision: 0.715855797749425\n",
      "Recall: 0.7038028923406534\n",
      "F1-score: 0.7002960419223117\n"
     ]
    }
   ],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Get the predicted labels\n",
    "y_pred = np.argmax(model2.predict(x_test), axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Model with relu , sigmoid and RMSprop\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71f63762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with elu,sigmoid and RMSprop\n",
      "Accuracy: 0.7155865024102839\n",
      "Precision: 0.714837888299071\n",
      "Recall: 0.7155865024102839\n",
      "F1-score: 0.7116966206396439\n"
     ]
    }
   ],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Get the predicted labels\n",
    "y_pred = np.argmax(model3.predict(x_test), axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Model with elu,sigmoid and RMSprop\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aeb4e0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with tanh and Adgrad \n",
      "Accuracy: 0.16256025709694696\n",
      "Precision: 0.14384065595968437\n",
      "Recall: 0.16256025709694696\n",
      "F1-score: 0.11170886323125936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Get the predicted labels\n",
    "y_pred = np.argmax(model4.predict(x_test), axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(\"Model with tanh and Adgrad \")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5e71d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
